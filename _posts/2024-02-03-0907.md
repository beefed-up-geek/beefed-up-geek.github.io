---
layout: single
title: "Mediapipe facial landmark Image"
categories: Image_Processing
tags: [Mediapipe, Image Processing]
---


# Mediapipe Image Facial landmark




## Understanding Mediapipe Facial landmarks
Meadiapipe's facial landmarks have their own unique orders of landmarks corresponding to the facial vectors of input image<br>
<img src='https://user-images.githubusercontent.com/80172338/147330227-97fbf8bd-dd73-4d5d-b98b-3ac2489c1759.jpg' width = "200" hight = "200">



*  Left Eyebrow = [70,63,105,66,107,55,65,52,53,46]
* Right Eyebrow = [300,293,334,296,336,285,295,282,283,276]
* Left Eye = [33,246,161,160,159,158,157,173,133,155,154,153,145,144,163,7]
* Right Eye = [263,466,388,387,386,385,384,398,362,382,381,380,374,373,390,249]
* Inner Lip = [78,191,80,81,82,13,312,311,310,415,308,324,318,402,317,14,87,178,88,95]
* Outer Lip = [61,185,40,39,37,0,267,269,270,409,291,375,321,405,314,17,84,181,91,146]
* Face Boundary = [10,338,297,332,284,251,389,356,454,323,361,288,397,365,379,378,400,377,152,148,176,149,150,136,172,58,132,93,234,127,162,21,54,103,67,109]
* Left iris = [468,469,470,471,472]
* Right iris = [473,474,475,476,477]
* Nose = [64,4,294]

for more information check out
[github k-m-irfan](https://github.com/k-m-irfan/simplified_mediapipe_face_landmarks)




## load Libraries required


1.   openCV (cv2)
2.   mediapipe



```python
import cv2
import mediapipe as mp
```

## call Mediapipe solutions


```python
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_face_mesh = mp.solutions.face_mesh
```

## load input data
images laoded can be more than one. paths of images are listed in the **IMAGE_FILES** variable


```python
from google.colab.patches import cv2_imshow
IMAGE_FILES = ['input.jpg']
cv2_imshow(cv2.imread('input.jpg', cv2.IMREAD_UNCHANGED))
```


​    
![png](\images\posts\20240203\input.jpg)
​    


## Draw the face meshes & save


```python
drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)
with mp_face_mesh.FaceMesh(
        static_image_mode=True,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5) as face_mesh:
    for idx, file in enumerate(IMAGE_FILES):
        image = cv2.imread(file)
        # 작업 전에 BGR 이미지를 RGB로 변환합니다.
        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

        # 이미지에 출력하고 그 위에 얼굴 그물망 경계점을 그립니다.
        if not results.multi_face_landmarks:
            continue
        annotated_image = image.copy()
        for face_landmarks in results.multi_face_landmarks:
            #print('face_landmarks:', face_landmarks)
            mp_drawing.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks,
                connections=mp_face_mesh.FACEMESH_TESSELATION,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_drawing_styles
                .get_default_face_mesh_tesselation_style())
            mp_drawing.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks,
                connections=mp_face_mesh.FACEMESH_CONTOURS,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_drawing_styles
                .get_default_face_mesh_contours_style())
            mp_drawing.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks,
                connections=mp_face_mesh.FACEMESH_IRISES,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_drawing_styles
                .get_default_face_mesh_iris_connections_style())
        cv2.imwrite('./output'+ '.png', annotated_image)
cv2_imshow(annotated_image)
```


​    
![png](\images\posts\20240203\output.jpg)
​    

